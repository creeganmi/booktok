{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c78c58a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6328434b",
   "metadata": {},
   "source": [
    "# TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a39e631e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\creeg\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\IPython\\core\\interactiveshell.py:3457: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# load in tweet df\n",
    "# https://drive.google.com/file/d/1vAkSbl2YtPau2r7LUMPaSEuNxqZ2Fxlu/view?usp=sharing\n",
    "\n",
    "# df_tweets = pd.read_csv('/Users/Mary/Desktop/NLP/Group Project/final_cleaned_tweets.csv')\n",
    "df_tweets = pd.read_csv('/Users/creeg/Downloads/final_cleaned_tweets.csv')\n",
    "del df_tweets[\"Unnamed: 0\"] # delete unnecessary index column from last write\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "688e9559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1276597"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df should have 1276597 records\n",
    "len(df_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b58d4cd",
   "metadata": {},
   "source": [
    "### tweet cleaning\n",
    "\n",
    "df should return: \n",
    "- 261010001 total characters before cleaning across 1276597 tweets\n",
    "- 162741884 total characters after cleaning across 951466 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e434f015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261010001 total characters before cleaning across 1276597 tweets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\creeg\\AppData\\Local\\Temp/ipykernel_15492/183405973.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_tweets['Text'] = df_tweets['Text'].str.replace(\"\\’\", \"\").str.strip()\n",
      "C:\\Users\\creeg\\AppData\\Local\\Temp/ipykernel_15492/183405973.py:40: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_tweets['Text'] = df_tweets['Text'].str.replace(punct_pattern, \"\").str.strip()\n",
      "C:\\Users\\creeg\\AppData\\Local\\Temp/ipykernel_15492/183405973.py:44: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_tweets['Text'] = df_tweets['Text'].str.replace(nums, \"\").str.strip()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162741884 total characters after cleaning across 951466 tweets\n"
     ]
    }
   ],
   "source": [
    "print(str(sum(df_tweets['Text'].map(len)))+ ' total characters before cleaning across '+str(len(df_tweets))+' tweets')\n",
    "\n",
    "\n",
    "# make text lowercase\n",
    "df_tweets['Text'] = df_tweets['Text'].str.lower() #.astype('unicode')\n",
    "\n",
    "# remove apostrophes, newline, non-ascii characters\n",
    "df_tweets['Text'] = df_tweets['Text'].str.replace(\"\\’\", \"\").str.strip() \n",
    "df_tweets['Text'] = df_tweets['Text'].str.replace(\"\\''\", \"\").str.strip() \n",
    "df_tweets['Text'] = df_tweets['Text'].str.replace(\"\\n\", \"\").str.strip() \n",
    "df_tweets.Text.str.encode('ascii', 'ignore').str.decode('ascii')\n",
    "\n",
    "\n",
    "### remove emoji\n",
    "import re\n",
    "\n",
    "regex_pattern = re.compile(pattern = \"[\"\n",
    "    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                       \"]+\", flags = re.UNICODE)\n",
    "\n",
    "df_tweets['Text'] = df_tweets['Text'].str.replace(regex_pattern, \"\").str.strip() \n",
    "\n",
    "\n",
    "# remove twitter handles (words in tweet that start with \"@\")\n",
    "# NOTE: this line must be above regext to remove all punctuation!\n",
    "df_tweets['Text'] = df_tweets['Text'].apply(lambda x: re.sub('(?:\\s)@[^, ]*', '', x))\n",
    "df_tweets['Text'] = df_tweets['Text'].apply(lambda x: re.sub('@[^, ]*', '', x))\n",
    "\n",
    "\n",
    "# remove all punctuation except asterisk\n",
    "import string\n",
    "\n",
    "remove = string.punctuation\n",
    "remove = remove.replace(\"*\", \"\") # don't remove hyphens\n",
    "punct_pattern = r\"[{}]\".format(remove) # create the pattern\n",
    "\n",
    "df_tweets['Text'] = df_tweets['Text'].str.replace(punct_pattern, \"\").str.strip() \n",
    "\n",
    "# remove numbers\n",
    "nums = pattern = r'[0-9]'\n",
    "df_tweets['Text'] = df_tweets['Text'].str.replace(nums, \"\").str.strip() \n",
    "\n",
    "# remove non-english characters\n",
    "def isEnglish(s):\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "df_tweets = df_tweets[df_tweets['Text'].apply(isEnglish)] \n",
    "\n",
    "\n",
    "\n",
    "print(str(sum(df_tweets['Text'].map(len)))+ ' total characters after cleaning across '+str(len(df_tweets))+' tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87b27ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-03-23 23:50:07+00:00</td>\n",
       "      <td>1506780360834748419</td>\n",
       "      <td>off to a great startthesevenhusbandsofevelynhu...</td>\n",
       "      <td>actuallydana</td>\n",
       "      <td>#booktok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-03-23 23:15:05+00:00</td>\n",
       "      <td>1506771544600719367</td>\n",
       "      <td>enoch by jarrod edge christian scifiprophecy o...</td>\n",
       "      <td>IAN_AuthorPromo</td>\n",
       "      <td>#booktok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-03-23 23:00:01+00:00</td>\n",
       "      <td>1506767752152985610</td>\n",
       "      <td>soooooo im on tiktok httpstcodyaeldna now ive ...</td>\n",
       "      <td>LovinSunshine97</td>\n",
       "      <td>#booktok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-03-23 22:52:17+00:00</td>\n",
       "      <td>1506765808218820610</td>\n",
       "      <td>guysi just hit k on my booktok account  bookto...</td>\n",
       "      <td>adorkablebooks</td>\n",
       "      <td>#booktok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-03-23 21:44:11+00:00</td>\n",
       "      <td>1506748670095548422</td>\n",
       "      <td>im officially on twitter books booktok</td>\n",
       "      <td>themelissablair</td>\n",
       "      <td>#booktok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Datetime             Tweet Id  \\\n",
       "0  2022-03-23 23:50:07+00:00  1506780360834748419   \n",
       "1  2022-03-23 23:15:05+00:00  1506771544600719367   \n",
       "2  2022-03-23 23:00:01+00:00  1506767752152985610   \n",
       "3  2022-03-23 22:52:17+00:00  1506765808218820610   \n",
       "5  2022-03-23 21:44:11+00:00  1506748670095548422   \n",
       "\n",
       "                                                Text         Username  \\\n",
       "0  off to a great startthesevenhusbandsofevelynhu...     actuallydana   \n",
       "1  enoch by jarrod edge christian scifiprophecy o...  IAN_AuthorPromo   \n",
       "2  soooooo im on tiktok httpstcodyaeldna now ive ...  LovinSunshine97   \n",
       "3  guysi just hit k on my booktok account  bookto...   adorkablebooks   \n",
       "5             im officially on twitter books booktok  themelissablair   \n",
       "\n",
       "    hashtag  \n",
       "0  #booktok  \n",
       "1  #booktok  \n",
       "2  #booktok  \n",
       "3  #booktok  \n",
       "5  #booktok  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7a461a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_yr_mth\n",
       " #Font         1\n",
       " #books        1\n",
       " #flowe        1\n",
       " #newgi        1\n",
       " @anuja        1\n",
       "#MadeWi        1\n",
       "#audibl        1\n",
       "#book #        4\n",
       "#rsamen        1\n",
       "2021-03    21061\n",
       "2021-04    85257\n",
       "2021-05    81819\n",
       "2021-06    84368\n",
       "2021-07    77629\n",
       "2021-08    79570\n",
       "2021-09    76929\n",
       "2021-10    72203\n",
       "2021-11    72933\n",
       "2021-12    74922\n",
       "2022-01    83107\n",
       "2022-02    75693\n",
       "2022-03    65961\n",
       "have al        1\n",
       "https:/        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add month year column and check how many tweets each month has\n",
    "df_tweets['tweet_yr_mth'] = df_tweets['Datetime'].str[:7]\n",
    "df_tweets.groupby(['tweet_yr_mth']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "473f8578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37100656 total characters across 224761 tweets in final set\n"
     ]
    }
   ],
   "source": [
    "# select tweets only from q1 2022\n",
    "q1 = ['2022-03', '2022-02', '2022-01']\n",
    "q1_2022 = df_tweets[df_tweets['tweet_yr_mth'].isin(q1)]\n",
    "\n",
    "# q1_2022 = df_tweets.loc[df_tweets['tweet_yr_mth'] == ['2022-03', '2022-02', '2022-01']]\n",
    "\n",
    "print(str(sum(q1_2022['Text'].map(len)))+ ' total characters across '+str(len(q1_2022))+' tweets in final set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4e9966e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_yr_mth\n",
       "2022-01    83107\n",
       "2022-02    75693\n",
       "2022-03    65961\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_2022.groupby(['tweet_yr_mth']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23770fd5",
   "metadata": {},
   "source": [
    "# CATALOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68a88797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in catalog\n",
    "# https://drive.google.com/file/d/1MRCN70GiMOah3XWyyz0s_vaDdB6DHaj6/view?usp=sharing\n",
    "# df_cat = pd.read_csv('/Users/Mary/Desktop/NLP/Group Project/adbl_catalog_final.csv')\n",
    "\n",
    "df_cat = pd.read_csv('/Users/creeg/Downloads/adbl_catalog_final.csv')\n",
    "del df_cat[\"Unnamed: 0\"] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc61c06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4945826 total book title characters and 203319 books\n",
      "1441558 total book title characters and 67104 books after dropping < 100 review titles\n"
     ]
    }
   ],
   "source": [
    "# df should have 203319 rows \n",
    "print(str(sum(df_cat['product_short_title'].map(len)))+ ' total book title characters and '+str(len(df_cat))+' books')\n",
    "df_cat.drop(df_cat[df_cat['rating_count'] < 100].index, inplace=True)\n",
    "print(str(sum(df_cat['product_short_title'].map(len)))+ ' total book title characters and '+str(len(df_cat))+' books after dropping < 100 review titles')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42b29c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_asin</th>\n",
       "      <th>product_short_title</th>\n",
       "      <th>product_author</th>\n",
       "      <th>release_date</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>legacy_genre</th>\n",
       "      <th>whitespace_ct</th>\n",
       "      <th>title_no_spaces</th>\n",
       "      <th>both_titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B07FSNSLZ1</td>\n",
       "      <td>where the crawdads sing</td>\n",
       "      <td>Delia Owens</td>\n",
       "      <td>2018-08-14</td>\n",
       "      <td>4.760701</td>\n",
       "      <td>193799</td>\n",
       "      <td>Romance</td>\n",
       "      <td>3</td>\n",
       "      <td>wherethecrawdadssing</td>\n",
       "      <td>('where the crawdads sing', 'wherethecrawdadss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B01I28NFEE</td>\n",
       "      <td>the subtle art of not giving a f*ck</td>\n",
       "      <td>Mark Manson</td>\n",
       "      <td>2016-09-13</td>\n",
       "      <td>4.516414</td>\n",
       "      <td>144510</td>\n",
       "      <td>Relationships, Parenting &amp; Personal Development</td>\n",
       "      <td>7</td>\n",
       "      <td>thesubtleartofnotgivingaf*ck</td>\n",
       "      <td>('the subtle art of not giving a f*ck', 'thesu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B07KKMNZCH</td>\n",
       "      <td>cant hurt me</td>\n",
       "      <td>David Goggins</td>\n",
       "      <td>2018-11-28</td>\n",
       "      <td>4.874660</td>\n",
       "      <td>139548</td>\n",
       "      <td>Relationships, Parenting &amp; Personal Development</td>\n",
       "      <td>2</td>\n",
       "      <td>canthurtme</td>\n",
       "      <td>('cant hurt me', 'canthurtme')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B017V4IM1G</td>\n",
       "      <td>harry potter and the sorcerers stone</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>2015-11-20</td>\n",
       "      <td>4.903521</td>\n",
       "      <td>139222</td>\n",
       "      <td>Science Fiction &amp; Fantasy</td>\n",
       "      <td>5</td>\n",
       "      <td>harrypotterandthesorcerersstone</td>\n",
       "      <td>('harry potter and the sorcerers stone', 'harr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B002UZZ93G</td>\n",
       "      <td>a game of thrones</td>\n",
       "      <td>George R.R. Martin</td>\n",
       "      <td>2003-12-09</td>\n",
       "      <td>4.757246</td>\n",
       "      <td>128418</td>\n",
       "      <td>Literature &amp; Fiction</td>\n",
       "      <td>3</td>\n",
       "      <td>agameofthrones</td>\n",
       "      <td>('a game of thrones', 'agameofthrones')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_asin                   product_short_title      product_author  \\\n",
       "0   B07FSNSLZ1               where the crawdads sing         Delia Owens   \n",
       "1   B01I28NFEE   the subtle art of not giving a f*ck         Mark Manson   \n",
       "2   B07KKMNZCH                          cant hurt me       David Goggins   \n",
       "3   B017V4IM1G  harry potter and the sorcerers stone        J.K. Rowling   \n",
       "4   B002UZZ93G                     a game of thrones  George R.R. Martin   \n",
       "\n",
       "  release_date    rating  rating_count  \\\n",
       "0   2018-08-14  4.760701        193799   \n",
       "1   2016-09-13  4.516414        144510   \n",
       "2   2018-11-28  4.874660        139548   \n",
       "3   2015-11-20  4.903521        139222   \n",
       "4   2003-12-09  4.757246        128418   \n",
       "\n",
       "                                      legacy_genre  whitespace_ct  \\\n",
       "0                                          Romance              3   \n",
       "1  Relationships, Parenting & Personal Development              7   \n",
       "2  Relationships, Parenting & Personal Development              2   \n",
       "3                        Science Fiction & Fantasy              5   \n",
       "4                             Literature & Fiction              3   \n",
       "\n",
       "                   title_no_spaces  \\\n",
       "0             wherethecrawdadssing   \n",
       "1     thesubtleartofnotgivingaf*ck   \n",
       "2                       canthurtme   \n",
       "3  harrypotterandthesorcerersstone   \n",
       "4                   agameofthrones   \n",
       "\n",
       "                                         both_titles  \n",
       "0  ('where the crawdads sing', 'wherethecrawdadss...  \n",
       "1  ('the subtle art of not giving a f*ck', 'thesu...  \n",
       "2                     ('cant hurt me', 'canthurtme')  \n",
       "3  ('harry potter and the sorcerers stone', 'harr...  \n",
       "4            ('a game of thrones', 'agameofthrones')  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad2962c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small bit of text cleaning that wasn't done when file was written\n",
    "df_cat[\"product_short_title\"] = df_cat[\"product_short_title\"].str.replace(\"\\'\", \"\").str.strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78ca22ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete and recreate title columns with newly cleaned text\n",
    "del df_cat[\"title_no_spaces\"] \n",
    "del df_cat[\"both_titles\"] \n",
    "df_cat[\"title_no_spaces\"] = df_cat[\"product_short_title\"].str.replace(\" \", \"\").str.strip() \n",
    "df_cat[\"both_titles\"] = list(zip(df_cat['product_short_title'], df_cat['title_no_spaces']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c376aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create catalog dictionary\n",
    "cat_dict = df_cat.set_index('product_asin').to_dict()['both_titles']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c29288",
   "metadata": {},
   "source": [
    "# ASIN to tweet assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29e5a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = q1_2022['Text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8ecab36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224761"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5eb713ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched = {\n",
    "    # For each key in the dictionary, create a new tuple\n",
    "    key: tuple(\n",
    "    # For the tweets, if there exists a string in the original tuple value that is a substring of that element, then retain it in the result.    \n",
    "        filter(lambda x: any(substr in x for substr in value), tweets))\n",
    "        for key, value in cat_dict.items()\n",
    "}\n",
    "\n",
    "# filter out all of the key-value pairs that have empty tuples for values using a dictionary comprehension. We could condense into one line, but I think it becomes pretty unreadable\n",
    "result = {key: value for key, value in matched.items() if value != ()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c54d8691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13521"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f247f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to json file\n",
    "import json\n",
    "with open('asin_to_tweet_assignment.json', 'w') as fp:\n",
    "    json.dump(result, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb2b8fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
